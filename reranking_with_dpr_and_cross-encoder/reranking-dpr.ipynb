{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "from transformers import LongformerTokenizer, LongformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 설정\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 저장 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# DPR 모델과 토크나이저 로드\n",
    "dpr_context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "dpr_context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "dpr_context_model.to(device)\n",
    "\n",
    "# Longformer 모델과 토크나이저 로드\n",
    "longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
    "longformer_model.to(device)\n",
    "longformer_model.eval()\n",
    "\n",
    "# 규칙 문장 벡터화 (DPR로 인코딩)\n",
    "def encode_contexts_dpr(rules):\n",
    "    inputs = dpr_context_tokenizer(rules, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = dpr_context_model(**inputs)\n",
    "    return outputs.pooler_output  # [CLS] 토큰의 벡터 반환\n",
    "\n",
    "# 규칙 문장 벡터화 (Longformer로 인코딩)\n",
    "def encode_contexts_longformer(rules, batch_size=4):\n",
    "    encoded_embeddings = []\n",
    "    for i in range(0, len(rules), batch_size):\n",
    "        batch_rules = rules[i:i + batch_size]\n",
    "        inputs = longformer_tokenizer(batch_rules, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = longformer_model(**inputs)\n",
    "        encoded_embeddings.append(outputs.last_hidden_state[:, 0, :])  # [CLS] 토큰의 벡터 반환\n",
    "    return torch.cat(encoded_embeddings, dim=0)\n",
    "\n",
    "# rule 데이터 가져오기\n",
    "data = 'data/aihub_rules_prev.json'\n",
    "with open(data, 'r', encoding=\"UTF-8\") as j:\n",
    "    aihub_rule = json.load(j)\n",
    "    \n",
    "normal_rule = aihub_rule['normal']\n",
    "abnormal_rule = aihub_rule['abnormal']\n",
    "combined_rules = normal_rule + abnormal_rule\n",
    "\n",
    "# DPR 임베딩 생성 및 저장\n",
    "context_embeddings_dpr = encode_contexts_dpr(combined_rules)\n",
    "torch.save(context_embeddings_dpr, 'context_embeddings_dpr.pt')\n",
    "\n",
    "# Longformer 임베딩 생성 및 저장\n",
    "context_embeddings_longformer = encode_contexts_longformer(combined_rules)\n",
    "torch.save(context_embeddings_longformer, 'context_embeddings_longformer.pt')\n",
    "\n",
    "print(\"임베딩 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# DPR 모델과 토크나이저 로드\n",
    "dpr_question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "dpr_question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "dpr_question_model.to(device)\n",
    "\n",
    "# Longformer 모델과 토크나이저 로드\n",
    "longformer_tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "longformer_model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
    "longformer_model.to(device)\n",
    "longformer_model.eval()\n",
    "\n",
    "# 쿼리 문장 벡터화 (DPR로 인코딩)\n",
    "def encode_query_dpr(query):\n",
    "    inputs = dpr_question_tokenizer(query, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = dpr_question_model(**inputs)\n",
    "    return outputs.pooler_output  # [CLS] 토큰의 벡터 반환\n",
    "\n",
    "# 쿼리 문장 벡터화 (Longformer로 인코딩)\n",
    "def encode_query_longformer(query):\n",
    "    inputs = longformer_tokenizer(query, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = longformer_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰의 벡터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(query_embedding, doc_embedding):\n",
    "    # 쿼리와 문서 간 유사도 계산 (예시)\n",
    "    return torch.dot(query_embedding.flatten(), doc_embedding.flatten()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rank_of_answer_in_dpr_results(final_indices_mapped, answer_index):\n",
    "    try:\n",
    "        return final_indices_mapped.index(answer_index) + 1\n",
    "    except ValueError:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 임베딩 불러오기\n",
    "context_embeddings_dpr = torch.load('context_embeddings_dpr.pt')\n",
    "context_embeddings_longformer = torch.load('context_embeddings_longformer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discreption 가져오기\n",
    "root_path = '/data1/sliver/jwsuh/construction_dataset/aihub/llava/llava_image_result_with_obj'\n",
    "files = sorted([i for i in os.listdir(root_path) if i.endswith('.json')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-K 리스트\n",
    "list_k = [1, 5, 10, 15, 20, 25, 30, 50]\n",
    "dpr_save_right_index = {}\n",
    "dpr_save_wrong_index = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:45<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 0.019088016967126194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:39<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy: 0.07529162248144221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:40<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 accuracy: 0.1474019088016967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:39<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-15 accuracy: 0.22905620360551432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:40<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 accuracy: 0.3329798515376458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:41<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-25 accuracy: 0.3944856839872747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:41<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 accuracy: 0.4750795334040297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:43<00:00,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-50 accuracy: 0.8197242841993637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 최종 top-K 평가\n",
    "for final_top_k in list_k:\n",
    "    correct = 0\n",
    "    dpr_save_right_index[final_top_k] = {}\n",
    "    dpr_save_wrong_index[final_top_k] = {}\n",
    "    ind = 0\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        with open(os.path.join(root_path, file), 'r', encoding=\"UTF-8\") as j:\n",
    "            caption = json.load(j)\n",
    "        query_embedding_dpr = encode_query_dpr(caption['outputs'])\n",
    "\n",
    "        # 초기 유사성 계산 (상위 50개 추출)\n",
    "        initial_top_k = 50\n",
    "        initial_similarities = torch.matmul(query_embedding_dpr, context_embeddings_dpr.T).squeeze(0)\n",
    "        initial_top_k_indices = torch.topk(initial_similarities, k=initial_top_k).indices\n",
    "\n",
    "        # 초기 상위 50개 문서에 대해 Longformer로 re-ranking 수행\n",
    "        re_ranked_embeddings = context_embeddings_longformer[initial_top_k_indices]\n",
    "        \n",
    "        # GPU 메모리 해제\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Re-ranked 유사성 계산 (상위 final_top_k 추출)\n",
    "        query_embedding_longformer = encode_query_longformer(caption['outputs'])\n",
    "        re_ranked_similarities = torch.matmul(query_embedding_longformer, re_ranked_embeddings.T).squeeze(0)\n",
    "        final_top_k_indices = torch.topk(re_ranked_similarities, k=final_top_k).indices\n",
    "\n",
    "        # 최종 상위 final_top_k개의 인덱스를 초기 상위 50개의 인덱스로 매핑\n",
    "        final_indices_mapped = [initial_top_k_indices[i].item() for i in final_top_k_indices]\n",
    "        saved_final_indices_mapped = [(initial_top_k_indices[i].item(), re_ranked_similarities[i].item()) for i in final_top_k_indices]\n",
    "        \n",
    "        answer = file.split('_')[2]\n",
    "        if answer[0] == 'Y':\n",
    "            answer_index = int(answer[2:]) - 1\n",
    "        elif answer[0] == 'N':\n",
    "            answer_index = int(answer[2:]) + 49\n",
    "\n",
    "        rank = find_rank_of_answer_in_dpr_results(final_indices_mapped, answer_index)\n",
    "\n",
    "        if rank <= final_top_k and rank != -1:\n",
    "            correct += 1\n",
    "            dpr_save_right_index[final_top_k][ind] = saved_final_indices_mapped\n",
    "        else:\n",
    "            dpr_save_wrong_index[final_top_k][ind] = saved_final_indices_mapped\n",
    "\n",
    "        ind += 1\n",
    "\n",
    "    print(f\"Top-{final_top_k} accuracy:\", correct / len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867aff4711e646128e9b3e2f3c101aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7f92c391d431e9f27283a10cf99e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0525d3b7db08460182cecb4484b59c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eca3d8e608943debed061e939815cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750c1ced3aaf4de8bec4b66011c60993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9122717e3ecd47c1bd90edacb5351caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 저장 완료\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# RoBERTa 모델과 토크나이저 로드\n",
    "roberta_tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = RobertaModel.from_pretrained('roberta-base')\n",
    "roberta_model.to(device)\n",
    "roberta_model.eval()\n",
    "\n",
    "def encode_query_roberta(query):\n",
    "    inputs = roberta_tokenizer(query, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰의 벡터 반환\n",
    "\n",
    "def encode_contexts_roberta(rules, batch_size=4):\n",
    "    encoded_embeddings = []\n",
    "    for i in range(0, len(rules), batch_size):\n",
    "        batch_rules = rules[i:i + batch_size]\n",
    "        inputs = roberta_tokenizer(batch_rules, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = roberta_model(**inputs)\n",
    "        encoded_embeddings.append(outputs.last_hidden_state[:, 0, :])  # [CLS] 토큰의 벡터 반환\n",
    "    return torch.cat(encoded_embeddings, dim=0)\n",
    "\n",
    "# RoBERTa 임베딩 생성 및 저장\n",
    "context_embeddings_roberta = encode_contexts_roberta(combined_rules)\n",
    "torch.save(context_embeddings_roberta, 'context_embeddings_roberta.pt')\n",
    "\n",
    "print(\"임베딩 저장 완료\")\n",
    "\n",
    "context_embeddings_roberta = torch.load('context_embeddings_roberta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/943 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:00<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 0.018027571580063628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:00<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 accuracy: 0.08483563096500531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:00<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 accuracy: 0.1728525980911983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:00<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-15 accuracy: 0.256627783669141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:01<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 accuracy: 0.3329798515376458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:02<00:00, 15.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-25 accuracy: 0.3997879109225875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:02<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-30 accuracy: 0.49522799575821846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [01:03<00:00, 14.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-50 accuracy: 0.8197242841993637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# top-K 리스트\n",
    "list_k = [1, 5, 10, 15, 20, 25, 30, 50]\n",
    "dpr_roberta_save_right_index = {}\n",
    "dpr_roberta_save_wrong_index = {}\n",
    "\n",
    "# 최종 top-K 평가\n",
    "for final_top_k in list_k:\n",
    "    correct = 0\n",
    "    dpr_roberta_save_right_index[final_top_k] = {}\n",
    "    dpr_roberta_save_wrong_index[final_top_k] = {}\n",
    "    ind = 0\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        with open(os.path.join(root_path, file), 'r', encoding=\"UTF-8\") as j:\n",
    "            caption = json.load(j)\n",
    "        query_embedding_dpr = encode_query_dpr(caption['outputs'])\n",
    "        query_embedding_roberta = encode_query_roberta(caption['outputs'])\n",
    "\n",
    "        # 초기 유사성 계산 (상위 50개 추출)\n",
    "        initial_top_k = 50\n",
    "        initial_similarities = torch.matmul(query_embedding_dpr, context_embeddings_dpr.T).squeeze(0)\n",
    "        initial_top_k_indices = torch.topk(initial_similarities, k=initial_top_k).indices\n",
    "\n",
    "        # 초기 상위 50개 문서에 대해 RoBERTa로 re-ranking 수행\n",
    "        re_ranked_embeddings_roberta = context_embeddings_roberta[initial_top_k_indices]\n",
    "        \n",
    "        # GPU 메모리 해제\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Re-ranked 유사성 계산 (상위 final_top_k 추출)\n",
    "        re_ranked_similarities_roberta = torch.matmul(query_embedding_roberta, re_ranked_embeddings_roberta.T).squeeze(0)\n",
    "        final_top_k_indices = torch.topk(re_ranked_similarities_roberta, k=final_top_k).indices\n",
    "\n",
    "        # 최종 상위 final_top_k개의 인덱스를 초기 상위 50개의 인덱스로 매핑\n",
    "        final_indices_mapped = [initial_top_k_indices[i].item() for i in final_top_k_indices]\n",
    "        saved_final_indices_mapped = [(initial_top_k_indices[i].item(), re_ranked_similarities_roberta[i].item()) for i in final_top_k_indices]\n",
    "        \n",
    "        answer = file.split('_')[2]\n",
    "        if answer[0] == 'Y':\n",
    "            answer_index = int(answer[2:]) - 1\n",
    "        elif answer[0] == 'N':\n",
    "            answer_index = int(answer[2:]) + 49\n",
    "\n",
    "        rank = find_rank_of_answer_in_dpr_results(final_indices_mapped, answer_index)\n",
    "\n",
    "        if rank <= final_top_k and rank != -1:\n",
    "            correct += 1\n",
    "            dpr_roberta_save_right_index[final_top_k][ind] = saved_final_indices_mapped\n",
    "        else:\n",
    "            dpr_roberta_save_wrong_index[final_top_k][ind] = saved_final_indices_mapped\n",
    "\n",
    "        ind += 1\n",
    "\n",
    "    print(f\"Top-{final_top_k} accuracy:\", correct / len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
